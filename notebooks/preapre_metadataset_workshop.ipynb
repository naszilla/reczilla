{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this notebook was used to create the meta-dataset for the workshop submission. Not needed for later work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zzzzzz/miniconda3/envs/recsys/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (13,14,16,17,31,32,38,40,41,42,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TIME_FORMAT = \"%Y%m%d_%H%M%S\"\n",
    "\n",
    "df = pd.read_csv(\"/Users/zzzzzz/research/active_projects/reczilla/results/results.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>alg_seed</th>\n",
       "      <th>cutoff_list</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>exception</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>hyperparameters_source</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>original_split_path</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_5</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_50</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_6</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_7</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_8</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_9</th>\n",
       "      <th>time</th>\n",
       "      <th>time_on_test</th>\n",
       "      <th>time_on_train</th>\n",
       "      <th>time_on_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>default</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>114.638383</td>\n",
       "      <td>11.768501</td>\n",
       "      <td>115.430055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_0</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>124.220636</td>\n",
       "      <td>13.444535</td>\n",
       "      <td>123.385043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_1</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>115.785270</td>\n",
       "      <td>11.932769</td>\n",
       "      <td>115.417125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_2</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>123.379156</td>\n",
       "      <td>12.692332</td>\n",
       "      <td>123.481905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_3</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>123.355272</td>\n",
       "      <td>14.126628</td>\n",
       "      <td>123.627794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               alg_name  alg_seed  \\\n",
       "4  UserKNNCF_asymmetric         0   \n",
       "5  UserKNNCF_asymmetric         0   \n",
       "6  UserKNNCF_asymmetric         0   \n",
       "7  UserKNNCF_asymmetric         0   \n",
       "8  UserKNNCF_asymmetric         0   \n",
       "\n",
       "                                         cutoff_list          dataset_name  \\\n",
       "4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "5  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "6  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "7  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "8  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "\n",
       "  exception          experiment_name hyperparameters_source  num_samples  \\\n",
       "4       NaN  full-experiment-knn-146                default          100   \n",
       "5       NaN  full-experiment-knn-146               random_0          100   \n",
       "6       NaN  full-experiment-knn-146               random_1          100   \n",
       "7       NaN  full-experiment-knn-146               random_2          100   \n",
       "8       NaN  full-experiment-knn-146               random_3          100   \n",
       "\n",
       "                                 original_split_path  param_alpha  ...  \\\n",
       "4  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "5  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "6  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "7  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "8  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "\n",
       "   test_metric_USERS_IN_GT_cut_5  test_metric_USERS_IN_GT_cut_50  \\\n",
       "4                            1.0                             1.0   \n",
       "5                            1.0                             1.0   \n",
       "6                            1.0                             1.0   \n",
       "7                            1.0                             1.0   \n",
       "8                            1.0                             1.0   \n",
       "\n",
       "   test_metric_USERS_IN_GT_cut_6 test_metric_USERS_IN_GT_cut_7  \\\n",
       "4                            1.0                           1.0   \n",
       "5                            1.0                           1.0   \n",
       "6                            1.0                           1.0   \n",
       "7                            1.0                           1.0   \n",
       "8                            1.0                           1.0   \n",
       "\n",
       "  test_metric_USERS_IN_GT_cut_8  test_metric_USERS_IN_GT_cut_9  \\\n",
       "4                           1.0                            1.0   \n",
       "5                           1.0                            1.0   \n",
       "6                           1.0                            1.0   \n",
       "7                           1.0                            1.0   \n",
       "8                           1.0                            1.0   \n",
       "\n",
       "              time time_on_test  time_on_train  time_on_val  \n",
       "4  20220417_233953   114.638383      11.768501   115.430055  \n",
       "5  20220417_233953   124.220636      13.444535   123.385043  \n",
       "6  20220417_233953   115.785270      11.932769   115.417125  \n",
       "7  20220417_233953   123.379156      12.692332   123.481905  \n",
       "8  20220417_233953   123.355272      14.126628   123.627794  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice by experiment name\n",
    "df_expt = df.loc[df[\"experiment_name\"].str.startswith(\"full-experiment-\"), :]\n",
    "\n",
    "df_expt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       alg_name               dataset_name  num_rows\n",
      "0                  CoClustering                AnimeReader       100\n",
      "1                  CoClustering         BookCrossingReader       100\n",
      "2                  CoClustering              CiaoDVDReader       100\n",
      "3                  CoClustering               DatingReader       100\n",
      "4                  CoClustering             EpinionsReader       100\n",
      "5                  CoClustering            FilmTrustReader       100\n",
      "6                  CoClustering               FrappeReader       100\n",
      "7                  CoClustering   GoogleLocalReviewsReader       100\n",
      "8                  CoClustering              GowallaReader       100\n",
      "9                  CoClustering              Jester2Reader       100\n",
      "10                 CoClustering               LastFMReader       100\n",
      "11                 CoClustering     MarketBiasAmazonReader       100\n",
      "12                 CoClustering   MarketBiasModClothReader       100\n",
      "13                 CoClustering       MovieTweetingsReader       100\n",
      "14                 CoClustering        Movielens100KReader       100\n",
      "15                 CoClustering         Movielens10MReader       100\n",
      "16                 CoClustering          Movielens1MReader       100\n",
      "17                 CoClustering         Movielens20MReader       100\n",
      "18                 CoClustering  MovielensHetrec2011Reader       100\n",
      "19                 CoClustering         NetflixPrizeReader       100\n",
      "20                 CoClustering              RecipesReader       100\n",
      "21                 CoClustering             WikilensReader       100\n",
      "22   DELF_EF_RecommenderWrapper                AnimeReader       100\n",
      "23   DELF_EF_RecommenderWrapper         BookCrossingReader       100\n",
      "24   DELF_EF_RecommenderWrapper              CiaoDVDReader       100\n",
      "25   DELF_EF_RecommenderWrapper               DatingReader       100\n",
      "26   DELF_EF_RecommenderWrapper             EpinionsReader       100\n",
      "27   DELF_EF_RecommenderWrapper            FilmTrustReader       100\n",
      "28   DELF_EF_RecommenderWrapper               FrappeReader       100\n",
      "29   DELF_EF_RecommenderWrapper   GoogleLocalReviewsReader       100\n",
      "..                          ...                        ...       ...\n",
      "560         UserKNNCF_euclidean         Movielens20MReader       100\n",
      "561         UserKNNCF_euclidean  MovielensHetrec2011Reader       100\n",
      "562         UserKNNCF_euclidean         NetflixPrizeReader       100\n",
      "563         UserKNNCF_euclidean              RecipesReader       100\n",
      "564         UserKNNCF_euclidean             WikilensReader       100\n",
      "565           UserKNNCF_jaccard              CiaoDVDReader       100\n",
      "566           UserKNNCF_jaccard            FilmTrustReader       100\n",
      "567           UserKNNCF_jaccard               FrappeReader       100\n",
      "568           UserKNNCF_tversky                AnimeReader       100\n",
      "569           UserKNNCF_tversky         BookCrossingReader       100\n",
      "570           UserKNNCF_tversky              CiaoDVDReader       100\n",
      "571           UserKNNCF_tversky               DatingReader       100\n",
      "572           UserKNNCF_tversky             EpinionsReader       100\n",
      "573           UserKNNCF_tversky            FilmTrustReader       100\n",
      "574           UserKNNCF_tversky               FrappeReader       100\n",
      "575           UserKNNCF_tversky   GoogleLocalReviewsReader       100\n",
      "576           UserKNNCF_tversky              GowallaReader       100\n",
      "577           UserKNNCF_tversky              Jester2Reader       100\n",
      "578           UserKNNCF_tversky               LastFMReader       100\n",
      "579           UserKNNCF_tversky     MarketBiasAmazonReader       100\n",
      "580           UserKNNCF_tversky   MarketBiasModClothReader       100\n",
      "581           UserKNNCF_tversky       MovieTweetingsReader       100\n",
      "582           UserKNNCF_tversky        Movielens100KReader       100\n",
      "583           UserKNNCF_tversky         Movielens10MReader       100\n",
      "584           UserKNNCF_tversky          Movielens1MReader       100\n",
      "585           UserKNNCF_tversky         Movielens20MReader       100\n",
      "586           UserKNNCF_tversky  MovielensHetrec2011Reader       100\n",
      "587           UserKNNCF_tversky         NetflixPrizeReader       100\n",
      "588           UserKNNCF_tversky              RecipesReader       100\n",
      "589           UserKNNCF_tversky             WikilensReader       100\n",
      "\n",
      "[590 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# how many experiments, and how many samples per experiment?\n",
    "# print(df_expt.groupby(\"experiment_name\").size().rename(\"num_rows\").reset_index())\n",
    "print(df_expt.groupby([\"alg_name\", \"dataset_name\"]).size().rename(\"num_rows\").reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zzzzzz/miniconda3/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/zzzzzz/miniconda3/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# just to be sure, create a column that joins the algorithm and dataset name\n",
    "df_expt.loc[:, \"alg_data_name\"] = df_expt[[\"alg_name\", \"dataset_name\"]].agg('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zzzzzz/miniconda3/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/zzzzzz/miniconda3/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# if there are any rows with no metrics, drop them...\n",
    "metric_col_list = [c for c in df_expt.columns if \"_metric_\" in c]\n",
    "\n",
    "df_expt.loc[:, \"all_na_metrics\"] = df_expt[metric_col_list].isna().all(axis=1)\n",
    "\n",
    "# drop cols with all na metrics\n",
    "df_expt = df_expt.loc[~df_expt[\"all_na_metrics\"], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### JUST FOR POST-HOC ANALYSIS: treat all UserKNN and ItemKNN algs as the same. this will make it look like there are about 5x more samples for all knn algs than the others\n",
    "df_expt.loc[df_expt[\"alg_name\"].str.contains(\"UserKNN\"), \"alg_name\"] = \"UserKNN\"\n",
    "df_expt.loc[df_expt[\"alg_name\"].str.contains(\"ItemKNN\"), \"alg_name\"] = \"ItemKNN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find the max and min metric for each alg-dataset combo (just in case there are any min metrics...)\n",
    "metric_col_list = [c for c in df_expt.columns if \"_metric_\" in c]\n",
    "\n",
    "agg_dict = {\n",
    "    metric: [\"min\", \"max\"]\n",
    "    for metric in metric_col_list\n",
    "}\n",
    "agg_dict[\"time_on_test\"] = \"median\"\n",
    "agg_dict[\"time_on_train\"] = \"median\"\n",
    "agg_dict[\"time_on_val\"] = \"median\"\n",
    "agg_dict[\"time_on_val\"] = \"size\"\n",
    "\n",
    "df_hpo = df_expt.groupby([\"dataset_name\", \"alg_name\"]).agg(agg_dict).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>alg_name</th>\n",
       "      <th>min_test_metric_ARHR_ALL_HITS_cut_1</th>\n",
       "      <th>max_test_metric_ARHR_ALL_HITS_cut_1</th>\n",
       "      <th>min_test_metric_ARHR_ALL_HITS_cut_10</th>\n",
       "      <th>max_test_metric_ARHR_ALL_HITS_cut_10</th>\n",
       "      <th>min_test_metric_ARHR_ALL_HITS_cut_15</th>\n",
       "      <th>max_test_metric_ARHR_ALL_HITS_cut_15</th>\n",
       "      <th>min_test_metric_ARHR_ALL_HITS_cut_2</th>\n",
       "      <th>max_test_metric_ARHR_ALL_HITS_cut_2</th>\n",
       "      <th>...</th>\n",
       "      <th>max_test_metric_USERS_IN_GT_cut_6</th>\n",
       "      <th>min_test_metric_USERS_IN_GT_cut_7</th>\n",
       "      <th>max_test_metric_USERS_IN_GT_cut_7</th>\n",
       "      <th>min_test_metric_USERS_IN_GT_cut_8</th>\n",
       "      <th>max_test_metric_USERS_IN_GT_cut_8</th>\n",
       "      <th>min_test_metric_USERS_IN_GT_cut_9</th>\n",
       "      <th>max_test_metric_USERS_IN_GT_cut_9</th>\n",
       "      <th>median_time_on_test</th>\n",
       "      <th>median_time_on_train</th>\n",
       "      <th>num_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnimeReader</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.463675</td>\n",
       "      <td>6201.424713</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnimeReader</td>\n",
       "      <td>EASE_R_Recommender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.059715</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.062664</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.043217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.782406</td>\n",
       "      <td>131.096352</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnimeReader</td>\n",
       "      <td>GlobalEffects</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.552996</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnimeReader</td>\n",
       "      <td>IALSRecommender</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>0.039374</td>\n",
       "      <td>0.039374</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.805024</td>\n",
       "      <td>3878.538749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnimeReader</td>\n",
       "      <td>ItemKNN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.070494</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.636642</td>\n",
       "      <td>13.685998</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name            alg_name  min_test_metric_ARHR_ALL_HITS_cut_1  \\\n",
       "0  AnimeReader        CoClustering                             0.000000   \n",
       "1  AnimeReader  EASE_R_Recommender                             0.000000   \n",
       "2  AnimeReader       GlobalEffects                             0.000187   \n",
       "3  AnimeReader     IALSRecommender                             0.015290   \n",
       "4  AnimeReader             ItemKNN                             0.000000   \n",
       "\n",
       "   max_test_metric_ARHR_ALL_HITS_cut_1  min_test_metric_ARHR_ALL_HITS_cut_10  \\\n",
       "0                             0.000043                              0.000092   \n",
       "1                             0.034277                              0.000442   \n",
       "2                             0.000187                              0.004560   \n",
       "3                             0.015290                              0.036573   \n",
       "4                             0.043915                              0.000002   \n",
       "\n",
       "   max_test_metric_ARHR_ALL_HITS_cut_10  min_test_metric_ARHR_ALL_HITS_cut_15  \\\n",
       "0                              0.000410                              0.000288   \n",
       "1                              0.059715                              0.000563   \n",
       "2                              0.004560                              0.005064   \n",
       "3                              0.036573                              0.039374   \n",
       "4                              0.070494                              0.000004   \n",
       "\n",
       "   max_test_metric_ARHR_ALL_HITS_cut_15  min_test_metric_ARHR_ALL_HITS_cut_2  \\\n",
       "0                              0.000673                             0.000007   \n",
       "1                              0.062664                             0.000079   \n",
       "2                              0.005064                             0.000245   \n",
       "3                              0.039374                             0.021842   \n",
       "4                              0.073168                             0.000000   \n",
       "\n",
       "   max_test_metric_ARHR_ALL_HITS_cut_2  ...  \\\n",
       "0                             0.000101  ...   \n",
       "1                             0.043217  ...   \n",
       "2                             0.000245  ...   \n",
       "3                             0.021842  ...   \n",
       "4                             0.054840  ...   \n",
       "\n",
       "   max_test_metric_USERS_IN_GT_cut_6  min_test_metric_USERS_IN_GT_cut_7  \\\n",
       "0                                1.0                                1.0   \n",
       "1                                1.0                                1.0   \n",
       "2                                1.0                                1.0   \n",
       "3                                1.0                                1.0   \n",
       "4                                1.0                                1.0   \n",
       "\n",
       "   max_test_metric_USERS_IN_GT_cut_7  min_test_metric_USERS_IN_GT_cut_8  \\\n",
       "0                                1.0                                1.0   \n",
       "1                                1.0                                1.0   \n",
       "2                                1.0                                1.0   \n",
       "3                                1.0                                1.0   \n",
       "4                                1.0                                1.0   \n",
       "\n",
       "   max_test_metric_USERS_IN_GT_cut_8  min_test_metric_USERS_IN_GT_cut_9  \\\n",
       "0                                1.0                                1.0   \n",
       "1                                1.0                                1.0   \n",
       "2                                1.0                                1.0   \n",
       "3                                1.0                                1.0   \n",
       "4                                1.0                                1.0   \n",
       "\n",
       "   max_test_metric_USERS_IN_GT_cut_9  median_time_on_test  \\\n",
       "0                                1.0           255.463675   \n",
       "1                                1.0           296.782406   \n",
       "2                                1.0           225.552996   \n",
       "3                                1.0           240.805024   \n",
       "4                                1.0           273.636642   \n",
       "\n",
       "   median_time_on_train  num_samples  \n",
       "0           6201.424713            5  \n",
       "1            131.096352           49  \n",
       "2              0.704396            1  \n",
       "3           3878.538749            1  \n",
       "4             13.685998          363  \n",
       "\n",
       "[5 rows x 665 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col_names = ['_'.join(reversed(col)).strip() for col in df_hpo.columns.values]\n",
    "new_col_names[0] = \"dataset_name\"\n",
    "new_col_names[1] = \"alg_name\"\n",
    "new_col_names[-1] = \"num_samples\"\n",
    "\n",
    "\n",
    "df_hpo.columns = new_col_names\n",
    "df_hpo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpo.to_csv(\"./performance_meta_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              alg_name  num_rows\n",
      "0                         CoClustering        20\n",
      "1           DELF_EF_RecommenderWrapper         4\n",
      "2                   EASE_R_Recommender        13\n",
      "3                        GlobalEffects        21\n",
      "4                      IALSRecommender        19\n",
      "5                              ItemKNN        21\n",
      "6    MatrixFactorization_AsySVD_Cython        15\n",
      "7       MatrixFactorization_BPR_Cython        21\n",
      "8   MatrixFactorization_FunkSVD_Cython        20\n",
      "9          Mult_VAE_RecommenderWrapper        11\n",
      "10                      NMFRecommender        19\n",
      "11                  P3alphaRecommender        20\n",
      "12                  PureSVDRecommender        21\n",
      "13                  RP3betaRecommender        20\n",
      "14                              Random        21\n",
      "15           SLIMElasticNetRecommender        17\n",
      "16                     SLIM_BPR_Cython        20\n",
      "17                            SlopeOne        12\n",
      "18                              TopPop        21\n",
      "19                             UserKNN        21\n"
     ]
    }
   ],
   "source": [
    "# how many datasets are there for each alg?\n",
    "print(df_hpo.groupby([\"alg_name\"]).size().rename(\"num_rows\").reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dataset_name  num_rows\n",
      "0                 AnimeReader        16\n",
      "1          BookCrossingReader        15\n",
      "2               CiaoDVDReader        19\n",
      "3                DatingReader        13\n",
      "4              EpinionsReader        16\n",
      "5             FilmTrustReader        20\n",
      "6                FrappeReader        20\n",
      "7               GowallaReader        12\n",
      "8               Jester2Reader        18\n",
      "9                LastFMReader        18\n",
      "10     MarketBiasAmazonReader        19\n",
      "11   MarketBiasModClothReader        19\n",
      "12       MovieTweetingsReader        16\n",
      "13        Movielens100KReader        20\n",
      "14         Movielens10MReader        17\n",
      "15          Movielens1MReader        19\n",
      "16         Movielens20MReader        15\n",
      "17  MovielensHetrec2011Reader        18\n",
      "18         NetflixPrizeReader        12\n",
      "19              RecipesReader        15\n",
      "20             WikilensReader        20\n"
     ]
    }
   ],
   "source": [
    "# ... and how many algs for each dataset?\n",
    "print(df_hpo.groupby([\"dataset_name\"]).size().rename(\"num_rows\").reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a49d437ec7d70416a2164b1de0841ecb25c4cf254d34094d737b88836beceb4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('recsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
