{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triage all errors caught during experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zzzzzz/miniconda3/envs/recsys/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (13,14,17,31,32,38,40,41,42,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TIME_FORMAT = \"%Y%m%d_%H%M%S\"\n",
    "\n",
    "df = pd.read_csv(\"/Users/zzzzzz/research/active_projects/reczilla/results/results.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>alg_seed</th>\n",
       "      <th>cutoff_list</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>exception</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>hyperparameters_source</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>original_split_path</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_5</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_50</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_6</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_7</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_8</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_9</th>\n",
       "      <th>time</th>\n",
       "      <th>time_on_test</th>\n",
       "      <th>time_on_train</th>\n",
       "      <th>time_on_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>default</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>114.638383</td>\n",
       "      <td>11.768501</td>\n",
       "      <td>115.430055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_0</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>124.220636</td>\n",
       "      <td>13.444535</td>\n",
       "      <td>123.385043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_1</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>115.785270</td>\n",
       "      <td>11.932769</td>\n",
       "      <td>115.417125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_2</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>123.379156</td>\n",
       "      <td>12.692332</td>\n",
       "      <td>123.481905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UserKNNCF_asymmetric</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>MovieTweetingsReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-experiment-knn-146</td>\n",
       "      <td>random_3</td>\n",
       "      <td>100</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220417_233953</td>\n",
       "      <td>123.355272</td>\n",
       "      <td>14.126628</td>\n",
       "      <td>123.627794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               alg_name  alg_seed  \\\n",
       "4  UserKNNCF_asymmetric         0   \n",
       "5  UserKNNCF_asymmetric         0   \n",
       "6  UserKNNCF_asymmetric         0   \n",
       "7  UserKNNCF_asymmetric         0   \n",
       "8  UserKNNCF_asymmetric         0   \n",
       "\n",
       "                                         cutoff_list          dataset_name  \\\n",
       "4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "5  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "6  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "7  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "8  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  MovieTweetingsReader   \n",
       "\n",
       "  exception          experiment_name hyperparameters_source  num_samples  \\\n",
       "4       NaN  full-experiment-knn-146                default          100   \n",
       "5       NaN  full-experiment-knn-146               random_0          100   \n",
       "6       NaN  full-experiment-knn-146               random_1          100   \n",
       "7       NaN  full-experiment-knn-146               random_2          100   \n",
       "8       NaN  full-experiment-knn-146               random_3          100   \n",
       "\n",
       "                                 original_split_path  param_alpha  ...  \\\n",
       "4  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "5  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "6  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "7  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "8  gs://reczilla-results/dataset-splits/splits-v3...          NaN  ...   \n",
       "\n",
       "   test_metric_USERS_IN_GT_cut_5  test_metric_USERS_IN_GT_cut_50  \\\n",
       "4                            1.0                             1.0   \n",
       "5                            1.0                             1.0   \n",
       "6                            1.0                             1.0   \n",
       "7                            1.0                             1.0   \n",
       "8                            1.0                             1.0   \n",
       "\n",
       "   test_metric_USERS_IN_GT_cut_6 test_metric_USERS_IN_GT_cut_7  \\\n",
       "4                            1.0                           1.0   \n",
       "5                            1.0                           1.0   \n",
       "6                            1.0                           1.0   \n",
       "7                            1.0                           1.0   \n",
       "8                            1.0                           1.0   \n",
       "\n",
       "  test_metric_USERS_IN_GT_cut_8  test_metric_USERS_IN_GT_cut_9  \\\n",
       "4                           1.0                            1.0   \n",
       "5                           1.0                            1.0   \n",
       "6                           1.0                            1.0   \n",
       "7                           1.0                            1.0   \n",
       "8                           1.0                            1.0   \n",
       "\n",
       "              time time_on_test  time_on_train  time_on_val  \n",
       "4  20220417_233953   114.638383      11.768501   115.430055  \n",
       "5  20220417_233953   124.220636      13.444535   123.385043  \n",
       "6  20220417_233953   115.785270      11.932769   115.417125  \n",
       "7  20220417_233953   123.379156      12.692332   123.481905  \n",
       "8  20220417_233953   123.355272      14.126628   123.627794  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice by experiment name\n",
    "df_expt = df.loc[df[\"experiment_name\"].str.startswith(\"full-experiment-\"), :]\n",
    "\n",
    "df_expt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for exceptions\n",
    "exception_list = list(df_expt[\"exception\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze all caught exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_es = [e for e in exception_list if \"MemoryError\" in str(e)]\n",
    "oom_es = [e for e in exception_list if \"OOM when allocating\" in str(e)]\n",
    "non_memory_es = [e for e in exception_list if \"MemoryError\" not in str(e) and \"OOM when allocating\" not in str(e)]\n",
    "tfidf_es = [e for e in exception_list if \"TF_IDF\" in str(e)]\n",
    "ials_es = [e for e in exception_list if \"IALSRecommender\" in str(e)]\n",
    "rp3_es = [e for e in exception_list if \"RP3betaRecommender\" in str(e)]\n",
    "NMFRecommender_es = [e for e in exception_list if \"NMFRecommender\" in str(e)]\n",
    "MultiVAE_es = [e for e in exception_list if \"MultiVAE_RecommenderWrapper\" in str(e)]\n",
    "ease_r_es = [e for e in exception_list if \"EASE_R_\" in str(e)]\n",
    "delf_es = [e for e in exception_list if \"DELF\" in str(e)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 402, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 50, in _evaluate_on_validation\n",
      "    current_fit_parameters\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 293, in _evaluate_on_validation\n",
      "    recommender_instance, train_time = self._fit_model(current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 283, in _fit_model\n",
      "    **current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/KNN/ItemKNNCFRecommender.py\", line 53, in fit\n",
      "    self.W_sparse = similarity.compute_similarity()\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Base/Similarity/Compute_Similarity.py\", line 126, in compute_similarity\n",
      "    return self.compute_similarity_object.compute_similarity(**args)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Base/Similarity/Compute_Similarity_Euclidean.py\", line 131, in compute_similarity\n",
      "    this_block_weights = self.dataMatrix.T.dot(item_data)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/scipy/sparse/base.py\", line 364, in dot\n",
      "    return self * other\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/scipy/sparse/base.py\", line 473, in __mul__\n",
      "    return self._mul_multivector(other)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/scipy/sparse/compressed.py\", line 477, in _mul_multivector\n",
      "    dtype=upcast_char(self.dtype.char, other.dtype.char))\n",
      "MemoryError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# len(non_memory_es)\n",
    "print(memory_es[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num exceptions: 2816\n",
      "--- total num memory exceptions: 1593\n",
      "algs: EASE_R_Recommender                   800\n",
      "DELF_EF_RecommenderWrapper           750\n",
      "NMFRecommender                        16\n",
      "ItemKNNCF_euclidean                   14\n",
      "SlopeOne                               6\n",
      "CoClustering                           3\n",
      "UserKNNCF_euclidean                    2\n",
      "MatrixFactorization_BPR_Cython         1\n",
      "MatrixFactorization_AsySVD_Cython      1\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: RecipesReader               209\n",
      "BookCrossingReader          205\n",
      "GoogleLocalReviewsReader    205\n",
      "GowallaReader               204\n",
      "EpinionsReader              201\n",
      "DatingReader                188\n",
      "Movielens20MReader          173\n",
      "NetflixPrizeReader          102\n",
      "MovieTweetingsReader        100\n",
      "Movielens10MReader            6\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num OOM (tensor?) exceptions: 194\n",
      "algs: DELF_EF_RecommenderWrapper    194\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: AnimeReader           100\n",
      "Movielens10MReader     80\n",
      "Jester2Reader          14\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num exceptions because of TF-IDF exceptions: 192\n",
      "algs: ItemKNNCF_cosine    100\n",
      "UserKNNCF_cosine     92\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: Jester2Reader    100\n",
      "AnimeReader       92\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num exceptions because  cd doesn't handle k-l: 296\n",
      "algs: NMFRecommender    296\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: MovielensHetrec2011Reader    28\n",
      "FrappeReader                 28\n",
      "LastFMReader                 28\n",
      "CiaoDVDReader                28\n",
      "MarketBiasAmazonReader       28\n",
      "MarketBiasModClothReader     28\n",
      "FilmTrustReader              28\n",
      "Movielens100KReader          28\n",
      "WikilensReader               28\n",
      "Movielens1MReader            26\n",
      "MovieTweetingsReader          6\n",
      "Movielens10MReader            4\n",
      "EpinionsReader                3\n",
      "RecipesReader                 2\n",
      "BookCrossingReader            1\n",
      "Movielens20MReader            1\n",
      "DatingReader                  1\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num exceptions because of NMFRecommender: 553\n",
      "algs: NMFRecommender    553\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: AnimeReader                  100\n",
      "Jester2Reader                100\n",
      "MarketBiasAmazonReader        42\n",
      "CiaoDVDReader                 39\n",
      "WikilensReader                36\n",
      "FilmTrustReader               30\n",
      "LastFMReader                  29\n",
      "FrappeReader                  29\n",
      "MovielensHetrec2011Reader     28\n",
      "Movielens100KReader           28\n",
      "MarketBiasModClothReader      28\n",
      "Movielens1MReader             26\n",
      "Movielens10MReader            10\n",
      "MovieTweetingsReader           8\n",
      "EpinionsReader                 4\n",
      "Movielens20MReader             4\n",
      "DatingReader                   4\n",
      "RecipesReader                  3\n",
      "GowallaReader                  2\n",
      "NetflixPrizeReader             2\n",
      "BookCrossingReader             1\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num exceptions because of IALSRecommender: 2\n",
      "algs: IALSRecommender    2\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: Jester2Reader    2\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num exceptions because of RP3betaRecommender: 100\n",
      "algs: RP3betaRecommender    100\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: AnimeReader      50\n",
      "Jester2Reader    50\n",
      "Name: dataset_name, dtype: int64\n",
      "--- total num exceptions because of MultiVAE_RecommenderWrapper: 100\n",
      "algs: Mult_VAE_RecommenderWrapper    100\n",
      "Name: alg_name, dtype: int64\n",
      "datasets: GoogleLocalReviewsReader    100\n",
      "Name: dataset_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how many exceptions? and how many memory errors\n",
    "print(f\"total num exceptions: {sum(~df_expt['exception'].isna())}\")\n",
    "print(f\"--- total num memory exceptions: {sum(df_expt['exception'].astype(str).str.contains('MemoryError'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('MemoryError')\n",
    "\n",
    "# alg_datsets = df_expt[x].apply(lambda row: row[\"alg_name\"] + \"---\" + row[\"dataset_name\"], axis=1)\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "print(f\"--- total num OOM (tensor?) exceptions: {sum(df_expt['exception'].astype(str).str.contains('OOM when allocating'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('OOM when allocating')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "print(f\"--- total num exceptions because of TF-IDF exceptions: {sum(df_expt['exception'].astype(str).str.contains('TF_IDF'))}\")\n",
    "\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('TF_IDF')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because  cd doesn't handle k-l: {sum(df_expt['exception'].astype(str).str.contains(' does not handle beta_loss = '))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains(' does not handle beta_loss = ')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because of NMFRecommender: {sum(df_expt['exception'].astype(str).str.contains('NMFRecommender'))}\")\n",
    "\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('NMFRecommender')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because of IALSRecommender: {sum(df_expt['exception'].astype(str).str.contains('IALSRecommender'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('IALSRecommender')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "print(f\"--- total num exceptions because of RP3betaRecommender: {sum(df_expt['exception'].astype(str).str.contains('RP3betaRecommender'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('RP3betaRecommender')\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because of MultiVAE_RecommenderWrapper: {sum(df_expt['exception'].astype(str).str.contains('MultiVAE_RecommenderWrapper'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('MultiVAE_RecommenderWrapper')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(NMFRecommender_es)\n",
    "# print(NMFRecommender_es[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[119829,1,11200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[{{node predict/GatherV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 402, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 50, in _evaluate_on_validation\n",
      "    current_fit_parameters\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 293, in _evaluate_on_validation\n",
      "    recommender_instance, train_time = self._fit_model(current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 283, in _fit_model\n",
      "    **current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_our_interface/DELFWrapper.py\", line 135, in fit\n",
      "    **earlystopping_kwargs)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Base/Incremental_Training_Early_Stopping.py\", line 177, in _train_with_early_stopping\n",
      "    self._run_epoch(epochs_current)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_our_interface/DELFWrapper.py\", line 177, in _run_epoch\n",
      "    self.rating_matrix: self.train_arr})\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[119829,1,11200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[node predict/GatherV2 (defined at /home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py:134) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "Caused by op 'predict/GatherV2', defined at:\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Experiment_handler/run_experiment.py\", line 109, in <module>\n",
      "    run(args)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Experiment_handler/run_experiment.py\", line 41, in run\n",
      "    time_limit=args.time_limit,\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Experiment_handler/Experiment.py\", line 469, in run_experiment\n",
      "    p.start()\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 165, in search\n",
      "    hyperparams, hyperparameters_source=f\"random_{i_sample}\"\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 402, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 50, in _evaluate_on_validation\n",
      "    current_fit_parameters\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 293, in _evaluate_on_validation\n",
      "    recommender_instance, train_time = self._fit_model(current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 283, in _fit_model\n",
      "    **current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_our_interface/DELFWrapper.py\", line 114, in fit\n",
      "    self.model = NMF.Model(self.input_user, self.input_item, self.output, self.num_users, self.num_items, self.rating_matrix, self.layers, self.batch_len)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py\", line 59, in __init__\n",
      "    self.predict\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py\", line 40, in decorator\n",
      "    setattr(self, attribute, function(self))\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py\", line 134, in predict\n",
      "    user_ratings = tf.reduce_sum(tf.gather(self.rating_matrix, self.input_user), axis=1)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 3273, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3748, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[119829,1,11200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[node predict/GatherV2 (defined at /home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py:134) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(delf_es[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_expt['exception'].astype(str).str.contains('EASE_R') & df_expt['exception'].astype(str).str.contains('sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a49d437ec7d70416a2164b1de0841ecb25c4cf254d34094d737b88836beceb4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('recsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
